{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba7d8123",
   "metadata": {},
   "source": [
    "# TASK 06 DESCRIPTION:\n",
    "## Create a program that perform below mentioned task upon recognizing a particular face. \n",
    "ðŸ“Œ When it recognize your face then - \n",
    "ðŸ‘‰ It send mail to your mail id by writing this is face of your_name. \n",
    "ðŸ‘‰ Second it send whatsapp message to your friend, it can be anything. \n",
    "\n",
    "ðŸ“Œ When it recognize second  face, it can be your friend or family members face.\n",
    "ðŸ‘‰ Create EC2 instance in the AWS using CLI. \n",
    "ðŸ‘‰ Create 5 GB EBS volume and attach it to the instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695546d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e45447",
   "metadata": {},
   "source": [
    "# FACE 1 IMAGE COLLECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a624aa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    #gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = model.detectMultiScale(img)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "        return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "\n",
    "    ret, photo = cap.read()\n",
    "    if face_extractor(photo) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(photo), (250, 250))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = './faces/user1/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "        #print(count)\n",
    "\n",
    "    # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "    else:\n",
    "        #print(\"Face not found\")\n",
    "        pass    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Collecting FACE 1 Samples Complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b4895b",
   "metadata": {},
   "source": [
    "# FACE 2 IMAGE COLLECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff79369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    #gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = model.detectMultiScale(img)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "        return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "\n",
    "    ret, photo = cap.read()\n",
    "    if face_extractor(photo) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(photo), (250, 250))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = './faces/user2/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "        #print(count)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "    else:\n",
    "        #print(\"Face not found\")\n",
    "        pass    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting FACE 2 Samples Complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a47e33",
   "metadata": {},
   "source": [
    "# TRAINING MODEL 1 AND 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8154bc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "face_model = []\n",
    "count = 1\n",
    "# Get the training data we previously made\n",
    "while True:\n",
    "    data_path = './faces/user'+str(count) + '/'\n",
    "    onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "# Create arrays for training data and labels\n",
    "    Training_Data, Labels = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "    for i, files in enumerate(onlyfiles):\n",
    "        image_path = data_path + onlyfiles[i]\n",
    "        images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "        Labels.append(i)\n",
    "\n",
    "# Create a numpy array for both training data and labels\n",
    "    Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "# Initialize facial recognizer\n",
    "# model = cv2.face.createLBPHFaceRecognizer()\n",
    "# NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "# pip install opencv-contrib-python\n",
    "# model = cv2.createLBPHFaceRecognizer()\n",
    "\n",
    "    face_model.append(cv2.face_LBPHFaceRecognizer.create())\n",
    "# Let's train our model \n",
    "    face_model[count-1].train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "    print(\"Model \"+str(count)+\" Successfully Trained..\")\n",
    "    count+= 1\n",
    "    if(count>2):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893232fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_data= [ [\"VARUN\", \"+919354822450\", \"vijayvarun779@gmail.com\"],\n",
    "             [\"TONY STARK\", \"+916397664364\",\"pepperbots250251@gmail.com\"]\n",
    "           ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0d27f7",
   "metadata": {},
   "source": [
    "# FUNCTION FOR SENDING WHATSAPP MSG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6d5f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywhatkit\n",
    "import datetime\n",
    "def whatsapp(i):\n",
    "    now = datetime.datetime.now()\n",
    "    Hr = int(now.strftime(\"%H\"))\n",
    "    Min = int(now.strftime(\"%M\")) + 1\n",
    "    pywhatkit.sendwhatmsg(team_data[i][1],\"Hello from whatsapp automation\",Hr,Min)\n",
    "    print(\"Msg sent to : \" + team_data[i][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cdbe54",
   "metadata": {},
   "source": [
    "# FUNCTION FOR SENDING EMAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61070f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib \n",
    "import mimetypes\n",
    "from email.message import EmailMessage\n",
    "import getpass\n",
    "def mail(i):\n",
    "    try:\n",
    "        message = EmailMessage()\n",
    "        sender = input(\" Enter Sender's Mail Address : \")\n",
    "        password = getpass.getpass(prompt='Enter password: ')\n",
    "        recipient = team_data[i][2]\n",
    "        message['From'] = sender\n",
    "        message['To'] = recipient\n",
    "        message['Subject'] = 'Face Detected !!'\n",
    "        body = \"This is face of\" + team_data[i][0] + \"!!!\"\n",
    "        message.set_content(body)\n",
    "        mime_type, _ = mimetypes.guess_type('face_img.jpg')\n",
    "        mime_type, mime_subtype = mime_type.split('/')\n",
    "        with open('face_img.jpg', 'rb') as file:\n",
    "            message.add_attachment(file.read(),\n",
    "            maintype=mime_type,\n",
    "            subtype=mime_subtype,\n",
    "            filename='face_img.jpg')\n",
    "        print(\"Mail Sent to : \" + team_data[i][2])\n",
    "        mail_server = smtplib.SMTP_SSL('smtp.gmail.com',465)\n",
    "        #mail_server.set_debuglevel(1)\n",
    "        mail_server.login(sender,password)\n",
    "        mail_server.send_message(message)\n",
    "        mail_server.quit()\n",
    "    except:\n",
    "        print(\"An Unexpected Error !!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c86dc8",
   "metadata": {},
   "source": [
    "# FUNCTION FOR AWS\n",
    "## CREATING EC2 INSTANCE\n",
    "## CREATING EBS VOLUME\n",
    "## ATTACHING VOLUME TO INSTNACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cde888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "def aws_instance():\n",
    "    key_name = input(\"Enter Key Name:- \")\n",
    "    az = input(\"Enter AZ Name:- \")\n",
    "    #subnet = input(\"Enter Subnet ID:- \")\n",
    "    size = input(\"Enter Disk Size: \")\n",
    "    os.system(\"aws ec2 run-instances --image-id ami-00bf4ae5a7909786c --instance-type t2.micro --count 1 --subnet-id subnet-323f365a --security-group-ids sg-0b02f2ebe1f44ac8a --key-name {} \".format(key_name))\n",
    "    time.sleep(20)\n",
    "    print(\"Launched EC2 instance..\")\n",
    "    id = os.popen('''aws ec2 describe-instances --filters Name=instance-state-name,Values=running --query \"Reservations[].Instances[].InstanceId\" --output text''').read()\n",
    "    time.sleep(15)\n",
    "    print(id)\n",
    "    os.system('aws ec2 create-volume --availability-zone ' + az +' --size ' + size)\n",
    "    print(\"Created EBS volume..\")\n",
    "    print(os.popen('''aws ec2 describe-volumes --filters Name=status,Values=available Name=size,Values={} --query \"Volumes[*].VolumeId\" --output text'''.format(size)).read())\n",
    "    inst_id = input(\"Enter Instance Id:- \")\n",
    "    vol_id = input(\"Enter Volume Id:- \")\n",
    "    dev_name = input(\"Enter Device Name:- \")\n",
    "    os.system('aws ec2 attach-volume --instance-id '+inst_id+' --volume-id '+ vol_id+' --device '+ dev_name)\n",
    "    print(\"Attached EBS volume to EC2 instance!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41ee786",
   "metadata": {},
   "source": [
    "# FACE RECOGNIZER FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde1f0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confidence(results):\n",
    "    confidence=[]\n",
    "    for i in range(0,2):\n",
    "        if results[i][1] < 500:\n",
    "            confidence.append(int( 100 * (1 - (results[i][1])/400) ))\n",
    "                                \n",
    "    for i in range(0,2):\n",
    "        if confidence[i] > 85:\n",
    "            display_string = str(confidence[i]) + '% Confident it is' + team_data[i][0]\n",
    "            cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "            cv2.putText(image, \"Hey\" + team_data[i][0], (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            cv2.waitKey(5)\n",
    "            if (i==0):\n",
    "                whatsapp(i)\n",
    "                mail(i)\n",
    "                break\n",
    "            else:\n",
    "                aws_instance()\n",
    "                break\n",
    "                \n",
    "    else:\n",
    "            \n",
    "            #cv2.putText(image, \"I dont know, how r u\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10995a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, photo = cap.read()\n",
    "    \n",
    "    image, face = face_detector(photo)\n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        results = []\n",
    "\n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "        cv2.imwrite(\"face_img.jpg\",face )\n",
    "        for i in range(0,2):\n",
    "            results.append(face_model[i].predict(face))\n",
    "        # harry_model.predict(face)\n",
    "        get_confidence(results)\n",
    "            \n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        #cv2.putText(image, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce43d28f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
